{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Loading and Sampling the desired layer\n",
    "tweets = pd.read_csv('../Data/tweets.csv', encoding='cp1252', header=None)\n",
    "tweets.columns = ['target','id','date','flag','username','text'] #Change column names to things that make sense\n",
    "tweets = tweets.drop(columns=['id','date','flag','username']) #Remove unneeded columns from memory\n",
    "tweets = tweets.replace({'target':{0:0,4:1}}) #Dataset has only 0=negative sent, 4=positive sent, remappping to 0,1 respectivly\n",
    "# print(tweets.shape)\n",
    "tweets = tweets.groupby('target').sample(10000,random_state=None)\n",
    "# print(tweets.shape)\n",
    "\n",
    "# Tokenizing the data\n",
    "# print(tweets.head())\n",
    "features = tokenizer(tweets['text'].values.tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='tf')\n",
    "# tweets['text'] = tweets['text'].apply(lambda x: tokenizer(x.lower(), padding=True, truncation=True, max_length=128, return_tensors='tf'))\n",
    "features = bert_model(**features).last_hidden_state[:,0,:]\n",
    "# print(\"ONE FEATURE ASPECT\")\n",
    "# # print(features[14:15, :])\n",
    "tweets['text'] = features.numpy().tolist()\n",
    "\n",
    "#split data into train and test sets\n",
    "X = np.array([x for x in tweets['text']])   # X = tweets.drop('target', axis=1)\n",
    "Y = np.array([x for x in tweets['target']])  # Y = tweets['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=265)\n",
    "\n",
    "#reduce dimensionality\n",
    "#try to increase feature size later\n",
    "# pca = PCA(n_components=3)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.fit_transform(X_test)\n",
    "\n",
    "X_train = (X_train - np.min(X_train))/(np.max(X_train) - np.min(X_train))\n",
    "X_test = (X_test - np.min(X_test))/(np.max(X_test) - np.min(X_test))\n",
    "\n",
    "print(type(X_train))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding, Input, Concatenate\n",
    "from tensorflow.keras.layers import Subtract\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# The transformer architecture \n",
    "class TransformerBlock(Layer): # inherit from Keras Layer\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super().__init__()\n",
    "        # setup the model heads and feedforward network\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, \n",
    "                                      key_dim=embed_dim)\n",
    "        \n",
    "        # make a two layer network that processes the attention\n",
    "        self.ffn = Sequential()\n",
    "        self.ffn.add( Dense(ff_dim, activation='relu') )\n",
    "        self.ffn.add( Dense(embed_dim) )\n",
    "        \n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # apply the layers as needed (similar to PyTorch)\n",
    "        \n",
    "        # get the attention output from multi heads\n",
    "        # Using same inpout here is self-attention\n",
    "        # call inputs are (query, value, key) \n",
    "        # if only two inputs given, value and key are assumed the same\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        \n",
    "        # create residual output, with attention\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        # apply dropout if training\n",
    "        out1 = self.dropout1(out1, training=training)\n",
    "        \n",
    "        # place through feed forward after layer norm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        # apply dropout if training\n",
    "        out2 = self.dropout2(out2, training=training)\n",
    "        #return the residual from Dense layer\n",
    "        return out2\n",
    "    \n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        # create two embeddings \n",
    "        # one for processing the tokens (words)\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, \n",
    "                                   output_dim=embed_dim)\n",
    "        # another embedding for processing the position\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, \n",
    "                                 output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        # create a static position measure (input)\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        # positions now goes from 0 to 500 (for IMdB) by 1\n",
    "        positions = self.pos_emb(positions)# embed these positions\n",
    "        x = self.token_emb(x) # embed the tokens\n",
    "        return x + positions # add embeddngs to get final embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 768)]             0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 768, 32)          27776     \n",
      " g_12 (TokenAndPositionEmbed                                     \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " transformer_block_12 (Trans  (None, 768, 32)          10656     \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 32)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_642 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 20)                660       \n",
      "                                                                 \n",
      " dropout_643 (Dropout)       (None, 20)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,113\n",
      "Trainable params: 39,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "top_words = 100\n",
    "NUM_CLASSES =  1\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = TokenAndPositionEmbedding(X_train.shape[1], top_words, embed_dim)(inputs)\n",
    "x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='sigmoid',\n",
    "              kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "model_xformer = Model(inputs=inputs, outputs=outputs)\n",
    "print(model_xformer.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.6954 - accuracy: 0.4938 - val_loss: 0.7101 - val_accuracy: 0.3750\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 3s 964ms/step - loss: 0.6914 - accuracy: 0.5312 - val_loss: 0.7072 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 3s 952ms/step - loss: 0.6945 - accuracy: 0.5188 - val_loss: 0.7130 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 3s 960ms/step - loss: 0.6831 - accuracy: 0.5562 - val_loss: 0.7128 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 3s 957ms/step - loss: 0.6876 - accuracy: 0.5813 - val_loss: 0.7199 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 3s 941ms/step - loss: 0.6870 - accuracy: 0.5375 - val_loss: 0.7548 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 3s 985ms/step - loss: 0.7171 - accuracy: 0.5188 - val_loss: 0.7525 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [70], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_xformer\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                       loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m                       metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m model_xformer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      7\u001b[0m     X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, \n\u001b[1;32m      8\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test)\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/tensorflow_2.9/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = Adam(learning_rate=1e-5)\n",
    "model_xformer.compile(optimizer='adam', \n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history = model_xformer.fit(\n",
    "    X_train, y_train, batch_size=64, epochs=30, \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# yhat_cnn = model_xformer.predict(X_test)\n",
    "yhat_xformer = model_xformer.predict(X_test)\n",
    "\n",
    "acc = [mt.accuracy_score(y_test,np.round(yhat_xformer))\n",
    "      ]\n",
    "\n",
    "plt.bar([1],acc)\n",
    "plt.xticks([1],['XFORMER1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(*name u get from model.summary*)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
